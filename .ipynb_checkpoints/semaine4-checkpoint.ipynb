{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4829de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import gym\n",
    "from gym import Env, spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7030aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### COLORS (BGR)\n",
    "BLUE =  [255, 0,   0]\n",
    "GREEN = [0,   255, 0]\n",
    "RED =   [0,   0,   255]\n",
    "WHITE = [255, 255, 255]\n",
    "GREY =  [240, 240, 240]\n",
    "BLACK = [0,   0,   0]\n",
    "\n",
    "#### BUILDINGS\n",
    "WASTELAND = 0\n",
    "OFFICE    = 1\n",
    "HOUSE     = 2\n",
    "\n",
    "#### REWARDS\n",
    "WASTING_TIME_REWARD = -100\n",
    "MOVE_REWARD         =  -1\n",
    "OFFICE_REWARD       =   5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29fab660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.paperspace.com/creating-custom-environments-openai-gym/\n",
    "# https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e\n",
    "\n",
    "class City(Env):\n",
    "    def __init__(self, observation_shape = (20, 4)):\n",
    "        super(City, self).__init__()\n",
    "        \n",
    "        self.observation_shape = observation_shape\n",
    "        self.observation_space = spaces.Box(low = 0, high = 2,\n",
    "            shape = (observation_shape[0] * observation_shape[1],), dtype = np.uint8)\n",
    "        \n",
    "        self.canvas_shape = 700, 700, 3 # width, height, color (BGR)\n",
    "        self.canvas = np.ones(self.canvas_shape, dtype = np.uint8) * 0\n",
    "        \n",
    "        #self.action_space = spaces.Tuple((\n",
    "        #     spaces.Discrete(self.observation_shape[0] * self.observation_shape[1]),\n",
    "        #     spaces.Discrete(self.observation_shape[0] * self.observation_shape[1])))\n",
    "        #self.action_space = spaces.Discrete(self.observation_shape[0] * self.observation_shape[1],)\n",
    "        self.action_space = spaces.Discrete(observation_shape[0] * observation_shape[1])\n",
    "        \n",
    "        # set the player's position in the middle of the map\n",
    "        self.position = self.observation_shape[0] // 2, self.observation_shape[1] // 2\n",
    "        \n",
    "        # \n",
    "        self.is_placing_house = True\n",
    "        \n",
    "        # set the map\n",
    "        self.map = np.ones(self.observation_shape, dtype = np.uint8) * WASTELAND\n",
    "        self.offices = []\n",
    "        self.houses = []\n",
    "        pass\n",
    "    \n",
    "    def reset(self, random_start = True, start_shape = (4, 4)):\n",
    "        \n",
    "        # reset the player's position in the middle of the map\n",
    "        self.position = self.observation_shape[0] // 2, self.observation_shape[1] // 2\n",
    "        \n",
    "        # \n",
    "        self.is_placing_house = True\n",
    "        \n",
    "        # reset the map with WASTELAND\n",
    "        self.map = np.ones(self.observation_shape, dtype = np.uint8) * WASTELAND\n",
    "        self.offices = []\n",
    "        self.houses = []\n",
    "        \n",
    "        # (re)place random houses and offices in the middle of the map\n",
    "        if random_start :            \n",
    "            for y in range((self.observation_shape[1] - start_shape[1]) // 2, (self.observation_shape[1] + start_shape[1]) // 2):\n",
    "                for x in range((self.observation_shape[0] - start_shape[0]) // 2, (self.observation_shape[0] + start_shape[0]) // 2):\n",
    "                    self.map[y, x] = random.randrange(3)\n",
    "                    if   self.map[y, x] == OFFICE : self.offices.append((x, y))\n",
    "                    elif self.map[y, x] == HOUSE  : self.houses.append((x, y))\n",
    "        \n",
    "        return self.map.flatten()\n",
    "    \n",
    "    def __search_nearest_office(self, position):\n",
    "        return int(min([math.dist(position, office) for office in self.offices]))\n",
    "    \n",
    "    def __search_nearest_house(self, position):\n",
    "        return int(min([math.dist(position, house) for house in self.houses]))\n",
    "    \n",
    "    # test if a position is occupied\n",
    "    def __is_free(self, position):\n",
    "        return self.map[position] == WASTELAND\n",
    "    \n",
    "    def __place(self):\n",
    "        \n",
    "        # give a bad reward to the player if his position is occupied\n",
    "        if not self.__is_free(self.position): return WASTING_TIME_REWARD\n",
    "        \n",
    "        if self.is_placing_house :\n",
    "            # place the house\n",
    "            self.houses.append(self.position)\n",
    "            self.map[self.position] = HOUSE\n",
    "\n",
    "            # calculate the reward\n",
    "            reward = self.__search_nearest_office(self.position)\n",
    "            reward = -reward + 5\n",
    "        else :\n",
    "            # place the office\n",
    "            self.offices.append(self.position)\n",
    "            self.map[self.position] = OFFICE\n",
    "            \n",
    "            reward = OFFICE_REWARD\n",
    "        \n",
    "        self.is_placing_house = not self.is_placing_house\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    # test if a position if out of bound\n",
    "    def __is_oob(self, position):\n",
    "        return not(0 <= position[0] < self.observation_shape[0]) \\\n",
    "            or not(0 <= position[1] < self.observation_shape[1])\n",
    "    \n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        \n",
    "        action_x, action_y = action % self.observation_shape[1], action // self.observation_shape[1]\n",
    "        self.position = (action_x, action_y)\n",
    "        \n",
    "        print(\"action\", action, \"\\nposition\", self.position, \"\\n\")\n",
    "        \n",
    "        reward = self.__place()\n",
    "        \n",
    "        # draw all elements on the canvas\n",
    "        self.draw_elements_on_canvas()\n",
    "        \n",
    "        #return self.canvas, reward\n",
    "        return self.map.flatten(), reward, reward == WASTING_TIME_REWARD, {}\n",
    "    \n",
    "    def __draw_element_on_canvas(self, x, y, color):\n",
    "        observation_width, observation_height = self.observation_shape\n",
    "        canvas_width, canvas_height, _ = self.canvas_shape\n",
    "\n",
    "        drawing_width = int(canvas_width / observation_width)\n",
    "        drawing_height = int(canvas_height / observation_height)\n",
    "\n",
    "        # fit element to the canvas\n",
    "        for j in range(y * drawing_height, y * drawing_height + drawing_height):\n",
    "            for i in range(x * drawing_width, x * drawing_width + drawing_width):\n",
    "                try : self.canvas[i, j] = color\n",
    "                except IndexError : pass\n",
    "                \n",
    "        for j in range(y * drawing_height, y * drawing_height + drawing_height):\n",
    "            try : self.canvas[x * drawing_width, j] = GREY\n",
    "            except IndexError : pass\n",
    "            \n",
    "        for i in range(x * drawing_width, x * drawing_width + drawing_width):\n",
    "            try : self.canvas[i, y * drawing_height] = GREY\n",
    "            except IndexError : pass\n",
    "        pass\n",
    "\n",
    "    def __draw_player_position(self, thickness = 3): # thickness must be odd \n",
    "        y, x = self.position\n",
    "        thickness_range = range(- (thickness // 2), thickness // 2 + 1)\n",
    "        \n",
    "        observation_width, observation_height = self.observation_shape\n",
    "        canvas_width, canvas_height, _ = self.canvas_shape\n",
    "\n",
    "        drawing_width = int(canvas_width / observation_width)\n",
    "        drawing_height = int(canvas_height / observation_height)\n",
    "        \n",
    "        for j in range(y * drawing_height, y * drawing_height + drawing_height):\n",
    "            try :\n",
    "                for t in thickness_range:\n",
    "                    self.canvas[x * drawing_width + t, j] = BLACK\n",
    "                    self.canvas[(x + 1) * drawing_width + t, j] = BLACK\n",
    "            except IndexError : pass\n",
    "\n",
    "        for i in range(x * drawing_width, x * drawing_width + drawing_width):\n",
    "            try :\n",
    "                for t in thickness_range:\n",
    "                    self.canvas[i, y * drawing_height + t] = BLACK\n",
    "                    self.canvas[i, (y + 1) * drawing_height + t] = BLACK\n",
    "            except IndexError : pass\n",
    "            \n",
    "        pass\n",
    "    \n",
    "    def draw_elements_on_canvas(self):\n",
    "        \n",
    "        # draw each element of the map\n",
    "        for y in range(len(self.map)):\n",
    "            for x in range(len(self.map[0])):\n",
    "                \n",
    "                color = WHITE\n",
    "                if   self.map[y, x] == OFFICE : color = BLUE\n",
    "                elif self.map[y, x] == HOUSE  : color = RED\n",
    "                \n",
    "                self.__draw_element_on_canvas(x, y, color)\n",
    "            pass\n",
    "               \n",
    "        # draw player's position\n",
    "        self.__draw_player_position()\n",
    "        pass\n",
    "    \n",
    "    def render(self, mode = \"console\"):\n",
    "        if mode == \"human\" :\n",
    "            cv2.imshow(\"\", self.canvas)\n",
    "            cv2.waitKey(1)\n",
    "        if mode == \"console\" :\n",
    "            print(self.position)\n",
    "    \n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27f33ad7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#env = City()\n",
    "#env.reset(random_start = True, start_shape = (4, 4))\n",
    "#env.draw_elements_on_canvas()\n",
    "\n",
    "#cv2.imshow(\"\", env.canvas)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77887238",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = City((16, 16))\n",
    "env.reset(random_start = True, start_shape = (4, 4))\n",
    "\n",
    "for _ in range(0):\n",
    "    env.step(env.action_space.sample())\n",
    "    env.render(\"human\")\n",
    "    #faudrai aussi potenciellement suprimer les duplicata\n",
    "    if (len(env.houses)+len(env.offices))>=(env.observation_shape[1]*env.observation_shape[1]):\n",
    "        env.reset()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "388c066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "696c7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 8 \n",
      "position (0, 1) \n",
      "\n",
      "action 41 \n",
      "position (1, 5) \n",
      "\n",
      "action 31 \n",
      "position (7, 3) \n",
      "\n",
      "action 60 \n",
      "position (4, 7) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 26 \n",
      "position (2, 3) \n",
      "\n",
      "action 56 \n",
      "position (0, 7) \n",
      "\n",
      "action 50 \n",
      "position (2, 6) \n",
      "\n",
      "action 12 \n",
      "position (4, 1) \n",
      "\n",
      "action 16 \n",
      "position (0, 2) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = City((8, 8))\n",
    "check_env(env) # test if the env is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7df52049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "action 28 \n",
      "position (4, 3) \n",
      "\n",
      "action 54 \n",
      "position (6, 6) \n",
      "\n",
      "action 7 \n",
      "position (7, 0) \n",
      "\n",
      "action 6 \n",
      "position (6, 0) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 1 \n",
      "position (1, 0) \n",
      "\n",
      "action 46 \n",
      "position (6, 5) \n",
      "\n",
      "action 25 \n",
      "position (1, 3) \n",
      "\n",
      "action 21 \n",
      "position (5, 2) \n",
      "\n",
      "action 3 \n",
      "position (3, 0) \n",
      "\n",
      "action 60 \n",
      "position (4, 7) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x18efc743790>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = City((8, 8))\n",
    "env = make_vec_env(lambda: env, n_envs = 1)\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10)\n",
    "#model.save(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cf553e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 25 \n",
      "position (1, 3) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 57 \n",
      "position (1, 7) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 57 \n",
      "position (1, 7) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 21 \n",
      "position (5, 2) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 57 \n",
      "position (1, 7) \n",
      "\n",
      "action 57 \n",
      "position (1, 7) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 6 \n",
      "position (6, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 56 \n",
      "position (0, 7) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 57 \n",
      "position (1, 7) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 57 \n",
      "position (1, 7) \n",
      "\n",
      "action 57 \n",
      "position (1, 7) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 20 \n",
      "position (4, 2) \n",
      "\n",
      "action 57 \n",
      "position (1, 7) \n",
      "\n",
      "action 57 \n",
      "position (1, 7) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n",
      "action 49 \n",
      "position (1, 6) \n",
      "\n",
      "action 0 \n",
      "position (0, 0) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render(\"human\")\n",
    "    \n",
    "    if cv2.waitKey(1) == 32 : break \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f9da5",
   "metadata": {},
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a51cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10)\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "#del model # remove to demonstrate saving and loading\n",
    "\n",
    "#model = PPO.load(\"ppo_cartpole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c732a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "env = City((10, 10))\n",
    "env.observation_space.sample()\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "\n",
    "def build_model(states, actions):\n",
    "    model = tensorflow.keras.Sequential()    \n",
    "    model.add(Dense(24, activation='relu', input_shape=((1,env.observation_shape[0], env.observation_shape[1]))))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model\n",
    "\n",
    "model = build_model(states, actions)\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=100, target_model_update=1e-2)\n",
    "    return dqn\n",
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=10000, visualize=True, verbose=1)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662644c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dqn.test(env, nb_episodes=10, visualize=True)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca441c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
