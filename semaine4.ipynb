{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4829de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import gym\n",
    "from gym import Env, spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7030aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### COLORS (BGR)\n",
    "BLUE =  [255, 0,   0]\n",
    "GREEN = [0,   255, 0]\n",
    "RED =   [0,   0,   255]\n",
    "WHITE = [255, 255, 255]\n",
    "GREY =  [240, 240, 240]\n",
    "BLACK = [0,   0,   0]\n",
    "\n",
    "#### BUILDINGS\n",
    "WASTELAND = 0\n",
    "OFFICE    = 1\n",
    "HOUSE     = 2\n",
    "\n",
    "#### REWARDS\n",
    "WASTING_TIME_REWARD = -100\n",
    "MOVE_REWARD         =  -1\n",
    "OFFICE_REWARD       =   5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fab660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.paperspace.com/creating-custom-environments-openai-gym/\n",
    "# https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e\n",
    "\n",
    "class City(Env):\n",
    "    def __init__(self, observation_shape = (20, 4)):\n",
    "        super(City, self).__init__()\n",
    "        \n",
    "        self.observation_shape = observation_shape\n",
    "        self.observation_space = spaces.Box(low = 0, high = 2,\n",
    "            shape = (observation_shape[0] * observation_shape[1],), dtype = np.uint8)\n",
    "        \n",
    "        self.canvas_shape = 700, 700, 3 # width, height, color (BGR)\n",
    "        self.canvas = np.ones(self.canvas_shape, dtype = np.uint8) * 0\n",
    "        \n",
    "        #self.action_space = spaces.Tuple((\n",
    "        #     spaces.Discrete(self.observation_shape[0] * self.observation_shape[1]),\n",
    "        #     spaces.Discrete(self.observation_shape[0] * self.observation_shape[1])))\n",
    "        #self.action_space = spaces.Discrete(self.observation_shape[0] * self.observation_shape[1],)\n",
    "        self.action_space = spaces.Discrete(observation_shape[0] * observation_shape[1])\n",
    "        \n",
    "        # set the player's position in the middle of the map\n",
    "        self.position = self.observation_shape[0] // 2, self.observation_shape[1] // 2\n",
    "        \n",
    "        # \n",
    "        self.is_placing_house = True\n",
    "        \n",
    "        # set the map\n",
    "        self.map = np.ones(self.observation_shape, dtype = np.uint8) * WASTELAND\n",
    "        self.offices = []\n",
    "        self.houses = []\n",
    "        pass\n",
    "    \n",
    "    def reset(self, random_start = True, start_shape = (4, 4)):\n",
    "        \n",
    "        # reset the player's position in the middle of the map\n",
    "        self.position = self.observation_shape[0] // 2, self.observation_shape[1] // 2\n",
    "        \n",
    "        # \n",
    "        self.is_placing_house = True\n",
    "        \n",
    "        # reset the map with WASTELAND\n",
    "        self.map = np.ones(self.observation_shape, dtype = np.uint8) * WASTELAND\n",
    "        self.offices = []\n",
    "        self.houses = []\n",
    "        \n",
    "        # (re)place random houses and offices in the middle of the map\n",
    "        if random_start :            \n",
    "            for y in range((self.observation_shape[1] - start_shape[1]) // 2, (self.observation_shape[1] + start_shape[1]) // 2):\n",
    "                for x in range((self.observation_shape[0] - start_shape[0]) // 2, (self.observation_shape[0] + start_shape[0]) // 2):\n",
    "                    self.map[y, x] = random.randrange(3)\n",
    "                    if   self.map[y, x] == OFFICE : self.offices.append((x, y))\n",
    "                    elif self.map[y, x] == HOUSE  : self.houses.append((x, y))\n",
    "        \n",
    "        return self.map.flatten()\n",
    "    \n",
    "    def __search_nearest_office(self, position):\n",
    "        return int(min([math.dist(position, office) for office in self.offices]))\n",
    "    \n",
    "    def __search_nearest_house(self, position):\n",
    "        return int(min([math.dist(position, house) for house in self.houses]))\n",
    "    \n",
    "    # test if a position is occupied\n",
    "    def __is_free(self, position):\n",
    "        return self.map[position] == WASTELAND\n",
    "    \n",
    "    def __place(self):\n",
    "        \n",
    "        # give a bad reward to the player if his position is occupied\n",
    "        if not self.__is_free(self.position): return WASTING_TIME_REWARD\n",
    "        \n",
    "        if self.is_placing_house :\n",
    "            # place the house\n",
    "            self.houses.append(self.position)\n",
    "            self.map[self.position] = HOUSE\n",
    "\n",
    "            # calculate the reward\n",
    "            reward = self.__search_nearest_office(self.position)\n",
    "            reward = -reward + 5\n",
    "        else :\n",
    "            # place the office\n",
    "            self.offices.append(self.position)\n",
    "            self.map[self.position] = OFFICE\n",
    "            \n",
    "            reward = OFFICE_REWARD\n",
    "        \n",
    "        self.is_placing_house = not self.is_placing_house\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    # test if a position if out of bound\n",
    "    def __is_oob(self, position):\n",
    "        return not(0 <= position[0] < self.observation_shape[0]) \\\n",
    "            or not(0 <= position[1] < self.observation_shape[1])\n",
    "    \n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        \n",
    "        action_x, action_y = action % self.observation_shape[1], action // self.observation_shape[1]\n",
    "        self.position = (action_x, action_y)\n",
    "        \n",
    "        #print(\"action\", action, \"\\nposition\", self.position, \"\\n\")\n",
    "        \n",
    "        reward = self.__place()\n",
    "        \n",
    "        # draw all elements on the canvas\n",
    "        self.draw_elements_on_canvas()\n",
    "        \n",
    "        #return self.canvas, reward\n",
    "        return self.map.flatten(), reward, reward == WASTING_TIME_REWARD, {}\n",
    "    \n",
    "    def __draw_element_on_canvas(self, x, y, color):\n",
    "        observation_width, observation_height = self.observation_shape\n",
    "        canvas_width, canvas_height, _ = self.canvas_shape\n",
    "\n",
    "        drawing_width = int(canvas_width / observation_width)\n",
    "        drawing_height = int(canvas_height / observation_height)\n",
    "\n",
    "        # fit element to the canvas\n",
    "        for j in range(y * drawing_height, y * drawing_height + drawing_height):\n",
    "            for i in range(x * drawing_width, x * drawing_width + drawing_width):\n",
    "                try : self.canvas[i, j] = color\n",
    "                except IndexError : pass\n",
    "                \n",
    "        for j in range(y * drawing_height, y * drawing_height + drawing_height):\n",
    "            try : self.canvas[x * drawing_width, j] = GREY\n",
    "            except IndexError : pass\n",
    "            \n",
    "        for i in range(x * drawing_width, x * drawing_width + drawing_width):\n",
    "            try : self.canvas[i, y * drawing_height] = GREY\n",
    "            except IndexError : pass\n",
    "        pass\n",
    "\n",
    "    def __draw_player_position(self, thickness = 3): # thickness must be odd \n",
    "        y, x = self.position\n",
    "        thickness_range = range(- (thickness // 2), thickness // 2 + 1)\n",
    "        \n",
    "        observation_width, observation_height = self.observation_shape\n",
    "        canvas_width, canvas_height, _ = self.canvas_shape\n",
    "\n",
    "        drawing_width = int(canvas_width / observation_width)\n",
    "        drawing_height = int(canvas_height / observation_height)\n",
    "        \n",
    "        for j in range(y * drawing_height, y * drawing_height + drawing_height):\n",
    "            try :\n",
    "                for t in thickness_range:\n",
    "                    self.canvas[x * drawing_width + t, j] = BLACK\n",
    "                    self.canvas[(x + 1) * drawing_width + t, j] = BLACK\n",
    "            except IndexError : pass\n",
    "\n",
    "        for i in range(x * drawing_width, x * drawing_width + drawing_width):\n",
    "            try :\n",
    "                for t in thickness_range:\n",
    "                    self.canvas[i, y * drawing_height + t] = BLACK\n",
    "                    self.canvas[i, (y + 1) * drawing_height + t] = BLACK\n",
    "            except IndexError : pass\n",
    "            \n",
    "        pass\n",
    "    \n",
    "    def draw_elements_on_canvas(self):\n",
    "        \n",
    "        # draw each element of the map\n",
    "        for y in range(len(self.map)):\n",
    "            for x in range(len(self.map[0])):\n",
    "                \n",
    "                color = WHITE\n",
    "                if   self.map[y, x] == OFFICE : color = BLUE\n",
    "                elif self.map[y, x] == HOUSE  : color = RED\n",
    "                \n",
    "                self.__draw_element_on_canvas(x, y, color)\n",
    "            pass\n",
    "               \n",
    "        # draw player's position\n",
    "        self.__draw_player_position()\n",
    "        pass\n",
    "    \n",
    "    def render(self, mode = \"console\"):\n",
    "        if mode == \"human\" :\n",
    "            cv2.imshow(\"\", self.canvas)\n",
    "            cv2.waitKey(1)\n",
    "        if mode == \"console\" :\n",
    "            print(self.position)\n",
    "    \n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f33ad7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#env = City()\n",
    "#env.reset(random_start = True, start_shape = (4, 4))\n",
    "#env.draw_elements_on_canvas()\n",
    "\n",
    "#cv2.imshow(\"\", env.canvas)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77887238",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = City((16, 16))\n",
    "env.reset(random_start = True, start_shape = (4, 4))\n",
    "\n",
    "for _ in range(0):\n",
    "    env.step(env.action_space.sample())\n",
    "    env.render(\"human\")\n",
    "    #faudrai aussi potenciellement suprimer les duplicata\n",
    "    if (len(env.houses)+len(env.offices))>=(env.observation_shape[1]*env.observation_shape[1]):\n",
    "        env.reset()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0b5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e66c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = City((8, 8))\n",
    "check_env(env) # test if the env is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b5a7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.75     |\n",
      "|    ep_rew_mean      | -93.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 11       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.62     |\n",
      "|    ep_rew_mean      | -89.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 29       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.42     |\n",
      "|    ep_rew_mean      | -90.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 41       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.25     |\n",
      "|    ep_rew_mean      | -91.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 52       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.9      |\n",
      "|    ep_rew_mean      | -92.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 58       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.92     |\n",
      "|    ep_rew_mean      | -88.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 94       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x1bc6611d640>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = City((8, 8))\n",
    "env = make_vec_env(lambda: env, n_envs = 1)\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=100)\n",
    "#model.save(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc4edb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9587eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 17 \n",
      "position (1, 2) \n",
      "\n",
      "action 17 \n",
      "position (1, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 54 \n",
      "position (6, 6) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 15 \n",
      "position (7, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 17 \n",
      "position (1, 2) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 54 \n",
      "position (6, 6) \n",
      "\n",
      "action 54 \n",
      "position (6, 6) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 10 \n",
      "position (2, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 11 \n",
      "position (3, 1) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n",
      "action 19 \n",
      "position (3, 2) \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-c80b5bf35753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"human\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \"\"\"\n\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mVecEnvStepReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\monitor.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-a8fdee69b2ae>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"action\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\nposition\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__place\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;31m# draw all elements on the canvas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-a8fdee69b2ae>\u001b[0m in \u001b[0;36m__place\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;31m# calculate the reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__search_nearest_office\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-a8fdee69b2ae>\u001b[0m in \u001b[0;36m__search_nearest_office\u001b[1;34m(self, position)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__search_nearest_office\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moffice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__search_nearest_house\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render(\"human\")\n",
    "    \n",
    "    if cv2.waitKey(1) == 32 : break \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f9da5",
   "metadata": {},
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547da974",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10)\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "#del model # remove to demonstrate saving and loading\n",
    "\n",
    "#model = PPO.load(\"ppo_cartpole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d8fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a5369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f79e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3018720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c732a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "env = City((10, 10))\n",
    "env.observation_space.sample()\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "\n",
    "def build_model(states, actions):\n",
    "    model = tensorflow.keras.Sequential()    \n",
    "    model.add(Dense(24, activation='relu', input_shape=((1,env.observation_shape[0], env.observation_shape[1]))))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model\n",
    "\n",
    "model = build_model(states, actions)\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=100, target_model_update=1e-2)\n",
    "    return dqn\n",
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=10000, visualize=True, verbose=1)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662644c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dqn.test(env, nb_episodes=10, visualize=True)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca441c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
